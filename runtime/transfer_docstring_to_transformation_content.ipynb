{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e13d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from enum import Enum\n",
    "from uuid import UUID, uuid4\n",
    "from keyword import iskeyword\n",
    "\n",
    "from pydantic import BaseModel, Field, ConstrainedStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71809ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, UUID):\n",
    "            return str(obj)\n",
    "        if isinstance(obj, datetime.datetime):\n",
    "            return pd.Timestamp(obj).isoformat()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f633bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataType(str, Enum):\n",
    "    \"\"\"hetida designer data types\n",
    "\n",
    "    These are the types available for component/workflow inputs/outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    Integer = \"INT\"\n",
    "    Float = \"FLOAT\"\n",
    "    String = \"STRING\"\n",
    "    DataFrame = \"DATAFRAME\"\n",
    "    Series = \"SERIES\"\n",
    "    Boolean = \"BOOLEAN\"\n",
    "    Any = \"ANY\"\n",
    "    PlotlyJson = \"PLOTLYJSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83727a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow only some special characters for category, description, name and version tag\n",
    "ALLOWED_CHARS_RAW_STRING = (\n",
    "    r\"\\w ,\\.\\-\\(\\)=/\"  # pylint: disable=anomalous-backslash-in-string\n",
    ")\n",
    "# The special sequence \\w matches unicode word characters;\n",
    "# this includes most characters that can be part of a word in any language, as well as numbers\n",
    "# and the underscore. If the ASCII flag is used, only [a-zA-Z0-9_] is matched.\n",
    "\n",
    "class NonEmptyValidStr(ConstrainedStr):\n",
    "    min_length = 1\n",
    "    max_length = 60\n",
    "    regex = re.compile(rf\"^[{ALLOWED_CHARS_RAW_STRING}]+$\")\n",
    "\n",
    "\n",
    "class ShortNonEmptyValidStr(ConstrainedStr):\n",
    "    min_length = 1\n",
    "    max_length = 20\n",
    "    regex = re.compile(rf\"^[{ALLOWED_CHARS_RAW_STRING}]+$\")\n",
    "\n",
    "\n",
    "class ValidStr(ConstrainedStr):\n",
    "    regex = re.compile(rf\"^[{ALLOWED_CHARS_RAW_STRING}]*$\")\n",
    "\n",
    "class ComponentInfo(BaseModel):\n",
    "    input_types_by_name: Dict[str, DataType]\n",
    "    output_types_by_name: Dict[str, DataType]\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    revision_group_id: UUID = Field(default_factory=uuid4)\n",
    "    name: NonEmptyValidStr\n",
    "    category: NonEmptyValidStr\n",
    "    description: ValidStr\n",
    "    version_tag: ShortNonEmptyValidStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8229820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(str, Enum):\n",
    "    \"\"\"Representing state of component/workflow\"\"\"\n",
    "\n",
    "    DRAFT = \"DRAFT\"\n",
    "    RELEASED = \"RELEASED\"\n",
    "    DISABLED = \"DISABLED\"\n",
    "\n",
    "\n",
    "class Type(str, Enum):\n",
    "    COMPONENT = \"COMPONENT\"\n",
    "    WORKFLOW = \"WORKFLOW\"\n",
    "    \n",
    "\n",
    "class IO(BaseModel):\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    name: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Must be a valid python identifier because it will be used for computation\",\n",
    "    )\n",
    "    data_type: DataType\n",
    "\n",
    "\n",
    "class IOInterface(BaseModel):\n",
    "    \"\"\"Represents combination of inputs and outputs.\n",
    "\n",
    "    Note: The names in the list of inputs and outputs must be unique, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs: List[IO] = []\n",
    "    outputs: List[IO] = []\n",
    "        \n",
    "\n",
    "class RefIdType(str, Enum):\n",
    "    \"\"\"Reference Id type as required for some adapters (notably generic rest adapter)\"\"\"\n",
    "\n",
    "    SOURCE = \"SOURCE\"\n",
    "    SINK = \"SINK\"\n",
    "    THINGNODE = \"THINGNODE\"\n",
    "\n",
    "    \n",
    "class ExternalType(str, Enum):\n",
    "    METADATA_INT = \"metadata(int)\"\n",
    "    METADATA_FLOAT = \"metadata(float)\"\n",
    "    METADATA_STR = \"metadata(str)\"\n",
    "    METADATA_BOOLEAN = \"metadata(bool)\"\n",
    "    METADATA_ANY = \"metadata(any)\"\n",
    "\n",
    "    TIMESERIES_INT = \"timeseries(int)\"\n",
    "    TIMESERIES_FLOAT = \"timeseries(float)\"\n",
    "    TIMESERIES_STR = \"timeseries(str)\"\n",
    "    TIMESERIES_BOOLEAN = \"timeseries(bool)\"\n",
    "    TIMESERIES_ANY = \"timeseries(any)\"\n",
    "\n",
    "    SERIES_INT = \"series(int)\"\n",
    "    SERIES_FLOAT = \"series(float)\"\n",
    "    SERIES_STR = \"series(str)\"\n",
    "    SERIES_BOOLEAN = \"series(bool)\"\n",
    "    SERIES_ANY = \"series(any)\"\n",
    "\n",
    "    DATAFRAME = \"dataframe\"\n",
    "    \n",
    "\n",
    "class InputWiring(BaseModel):\n",
    "    workflow_input_name: str = Field(..., alias=\"workflow_input_name\")\n",
    "    adapter_id: Union[int, str] = Field(..., alias=\"adapter_id\")\n",
    "\n",
    "    ref_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Id referencing the source in external systems.\"\n",
    "            \" Not necessary for direct provisioning.\"\n",
    "        ),\n",
    "    )\n",
    "    ref_id_type: Optional[RefIdType] = Field(\n",
    "        None,\n",
    "        description=\"Required if type is specified and is a metadata type. \"\n",
    "        \"Then describes to what kind of object in the tree the metadatum is attached. \"\n",
    "        \"Must then be one of \"\n",
    "        \", \".join(['\"' + x.value + '\"' for x in list(RefIdType)]),\n",
    "    )\n",
    "    ref_key: Optional[str] = None\n",
    "    type: Optional[ExternalType] = Field(\n",
    "        None,\n",
    "        description=\"Type of data. If present then must be one of \"\n",
    "        + \", \".join(['\"' + x.value + '\"' for x in list(ExternalType)]),\n",
    "    )\n",
    "    filters: dict = {}\n",
    "        \n",
    "        \n",
    "class OutputWiring(BaseModel):\n",
    "    workflow_output_name: str = Field(..., alias=\"workflow_output_name\")\n",
    "    adapter_id: Union[int, str] = Field(..., alias=\"adapter_id\")\n",
    "    ref_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Id referencing the sink in external systems.\"\n",
    "            \" Not necessary for direct provisioning.\"\n",
    "        ),\n",
    "    )\n",
    "    ref_id_type: Optional[RefIdType] = Field(\n",
    "        None,\n",
    "        description=\"Required if type is specified and is a metadata type. \"\n",
    "        \"Then describes to what kind of object in the tree the metadatum is attached. \"\n",
    "        \"Must then be one of \"\n",
    "        \", \".join(['\"' + x.value + '\"' for x in list(RefIdType)]),\n",
    "    )\n",
    "    ref_key: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Required if type is specified and is a metadata type. \"\n",
    "        \"Then is the key of the metdatum.\",\n",
    "    )\n",
    "    type: Optional[ExternalType] = Field(\n",
    "        None,\n",
    "        description=\"Type of data. If present then must be one of \"\n",
    "        + \", \".join(['\"' + x.value + '\"' for x in list(ExternalType)]),\n",
    "    )\n",
    "        \n",
    "        \n",
    "class WorkflowWiring(BaseModel):\n",
    "    input_wirings: List[InputWiring] = []\n",
    "    output_wirings: List[OutputWiring] = []\n",
    "        \n",
    "\n",
    "class TransformationRevision(BaseModel):\n",
    "    \"\"\"Either a component revision or a workflow revision\n",
    "\n",
    "    Both can be instantiated as an operator in a workflow revision\n",
    "    (yes, workflow in workflow in workflow... is possible) and are therefore\n",
    "    able to transform input data to output result data.\n",
    "\n",
    "    Note that there is no actual component or workflow entity, only revisions. Revisions are tied\n",
    "    together via the group id, and otherwise do not need to have anything in common, i.e. their\n",
    "    name and their interface etc. can differ completely.\n",
    "\n",
    "    Revisions with state RELEASED are what makes execution reproducible - they cannot be edited any\n",
    "    more and only they can be instantiated as operators.\n",
    "\n",
    "    Additionally RELEASED revisions cannot be deleted, but their state can be changed to\n",
    "    DISABLED. DISABLED revisions cannot be instantiated as new operators anymore but existing\n",
    "    operators from them still work (for reproducibility). Note that in the Frontend the DISABLED\n",
    "    state is called \"DEPRECATED\". The frontend then allows to replace deprecated operators by other\n",
    "    (possibly newer) released revisions from the the same revision group (i.e. same group id).\n",
    "    \"\"\"\n",
    "\n",
    "    id: UUID\n",
    "    revision_group_id: UUID\n",
    "    name: str\n",
    "    description: str = \"\"\n",
    "    category: str = Field(\n",
    "        \"Other\",\n",
    "        description='Category in which this is classified, i.e. the \"drawer\" in the User Interface',\n",
    "    )\n",
    "    version_tag: str\n",
    "    released_timestamp: Optional[datetime.datetime] = Field(\n",
    "        None,\n",
    "        description=\"If the revision is RELEASED then this should be release timestamp\",\n",
    "    )\n",
    "\n",
    "    disabled_timestamp: Optional[datetime.datetime] = Field(\n",
    "        None,\n",
    "        description=\"If the revision is DISABLED then this should be disable/deprecation timestamp\",\n",
    "    )\n",
    "    state: State = Field(\n",
    "        ...,\n",
    "        description=\"one of \" + \", \".join(['\"' + x.value + '\"' for x in list(State)]),\n",
    "    )\n",
    "    type: Type = Field(\n",
    "        ...,\n",
    "        description=\"one of \" + \", \".join(['\"' + x.value + '\"' for x in list(Type)]),\n",
    "    )\n",
    "\n",
    "    documentation: str = Field(\n",
    "        (\n",
    "            \"\\n\"\n",
    "            \"# New Component/Workflow\\n\"\n",
    "            \"## Description\\n\"\n",
    "            \"## Inputs\\n\"\n",
    "            \"## Outputs\\n\"\n",
    "            \"## Details\\n\"\n",
    "            \"## Examples\\n\"\n",
    "        ),\n",
    "        description=\"Documentation in markdown format.\",\n",
    "    )\n",
    "    content: str\n",
    "\n",
    "    io_interface: IOInterface = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"In case of type WORKFLOW determined from content. \"\n",
    "            \"To change from state DRAFT to state RELEASED all inputs and outputs must have names.\"\n",
    "        ),\n",
    "    )\n",
    "        \n",
    "    test_wiring: WorkflowWiring = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"The input and output wirings must match \"\n",
    "            \"the inputs and outputs of the io_interface\"\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9befd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json(path):\n",
    "    try:\n",
    "        with open(path, encoding=\"utf-8\") as f:\n",
    "            workflow_json = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        logger.error(\"Could not find json file at path %s\", path)\n",
    "        workflow_json = None\n",
    "    return workflow_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf82309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_files = []\n",
    "for root, _, files in os.walk(\"./transformations/components\"):\n",
    "    for file in files:\n",
    "        json_files.append(os.path.join(root, file))\n",
    "        print(json_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ecda03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def io_match(component_ios, tr_ios):\n",
    "    if len(component_ios) != len(tr_ios):\n",
    "        return False\n",
    "    tr_ios_by_name = {io.name: io for io in tr_ios}\n",
    "    \n",
    "    for cp_io in component_ios:\n",
    "        if cp_io[\"name\"] in tr_ios_by_name:\n",
    "            if cp_io[\"type\"] != tr_ios_by_name[cp_io[\"name\"]].data_type:\n",
    "                return False\n",
    "        else:\n",
    "            print\n",
    "            return False\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a2efe2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json_file_by_name = {}\n",
    "tr_by_name = {}\n",
    "\n",
    "for file in json_files:\n",
    "    tr_json = load_json(file)\n",
    "    tr = TransformationRevision(**tr_json)\n",
    "    if tr.name in json_file_by_name:\n",
    "        raise Exception(\"Name\", tr.name, \"is not unique!\")\n",
    "    json_file_by_name[tr.name] = file\n",
    "    tr_by_name[tr.name] = tr\n",
    "\n",
    "for component_name, json_file in json_file_by_name.items():\n",
    "    component_json = load_json(json_file)\n",
    "    tr = TransformationRevision(**component_json)\n",
    "    old_code = tr_component.content\n",
    "    if \">>>\" in old_code:\n",
    "        split_at_low_string = \"    # ***** DO NOT EDIT LINES ABOVE *****\\n\"\n",
    "        split_at_top_string = '    \"\"\" Usage example:\\n'\n",
    "        docstring = '    \"\"\" Usage example:\\n'+old_code.split(\n",
    "            split_at_top_string\n",
    "        )[1].split(split_at_low_string)[0]\n",
    "        split_code_top, split_code_low = tr.content.split(split_at_top_string)\n",
    "        _, split_code_low = split_code_low.split(split_at_low_string)\n",
    "        tr_content = split_code_top + split_at_low_string + docstring + split_code_low\n",
    "        print(tr_content)\n",
    "        tr.content = tr_content\n",
    "        tr_json = json.dumps(tr.dict(exclude_unset=True), cls=TREncoder, indent=2, sort_keys=True)\n",
    "        with open(json_file_by_name[component_name], \"w\", encoding=\"utf8\") as f:\n",
    "            json.dump(json.loads(tr_json), f, cls=TREncoder, indent=2, sort_keys=True)\n",
    "    else:\n",
    "        print(tr_component.name+\": seems to have no doctest docstring\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7ff12a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
