{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7e13d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "from typing import Optional, List, Dict, Union\n",
    "from enum import Enum\n",
    "from uuid import UUID, uuid4\n",
    "from keyword import iskeyword\n",
    "\n",
    "from pydantic import BaseModel, Field, ConstrainedStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f356148",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TREncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        if isinstance(obj, UUID):\n",
    "            return str(obj)\n",
    "        if isinstance(obj, datetime.datetime):\n",
    "            return pd.Timestamp(obj).isoformat()\n",
    "        return json.JSONEncoder.default(self, obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f633bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataType(str, Enum):\n",
    "    \"\"\"hetida designer data types\n",
    "\n",
    "    These are the types available for component/workflow inputs/outputs.\n",
    "    \"\"\"\n",
    "\n",
    "    Integer = \"INT\"\n",
    "    Float = \"FLOAT\"\n",
    "    String = \"STRING\"\n",
    "    DataFrame = \"DATAFRAME\"\n",
    "    Series = \"SERIES\"\n",
    "    Boolean = \"BOOLEAN\"\n",
    "    Any = \"ANY\"\n",
    "    PlotlyJson = \"PLOTLYJSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83727a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allow only some special characters for category, description, name and version tag\n",
    "ALLOWED_CHARS_RAW_STRING = (\n",
    "    r\"\\w ,\\.\\-\\(\\)=/\"  # pylint: disable=anomalous-backslash-in-string\n",
    ")\n",
    "# The special sequence \\w matches unicode word characters;\n",
    "# this includes most characters that can be part of a word in any language, as well as numbers\n",
    "# and the underscore. If the ASCII flag is used, only [a-zA-Z0-9_] is matched.\n",
    "\n",
    "class NonEmptyValidStr(ConstrainedStr):\n",
    "    min_length = 1\n",
    "    max_length = 60\n",
    "    regex = re.compile(rf\"^[{ALLOWED_CHARS_RAW_STRING}]+$\")\n",
    "\n",
    "\n",
    "class ShortNonEmptyValidStr(ConstrainedStr):\n",
    "    min_length = 1\n",
    "    max_length = 20\n",
    "    regex = re.compile(rf\"^[{ALLOWED_CHARS_RAW_STRING}]+$\")\n",
    "\n",
    "\n",
    "class ValidStr(ConstrainedStr):\n",
    "    regex = re.compile(rf\"^[{ALLOWED_CHARS_RAW_STRING}]*$\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8229820",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(str, Enum):\n",
    "    \"\"\"Representing state of component/workflow\"\"\"\n",
    "\n",
    "    DRAFT = \"DRAFT\"\n",
    "    RELEASED = \"RELEASED\"\n",
    "    DISABLED = \"DISABLED\"\n",
    "\n",
    "\n",
    "class Type(str, Enum):\n",
    "    COMPONENT = \"COMPONENT\"\n",
    "    WORKFLOW = \"WORKFLOW\"\n",
    "    \n",
    "\n",
    "class IO(BaseModel):\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    name: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Must be a valid python identifier because it will be used for computation\",\n",
    "    )\n",
    "    data_type: DataType\n",
    "\n",
    "\n",
    "class IOInterface(BaseModel):\n",
    "    \"\"\"Represents combination of inputs and outputs.\n",
    "\n",
    "    Note: The names in the list of inputs and outputs must be unique, respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    inputs: List[IO] = []\n",
    "    outputs: List[IO] = []\n",
    "        \n",
    "\n",
    "class RefIdType(str, Enum):\n",
    "    \"\"\"Reference Id type as required for some adapters (notably generic rest adapter)\"\"\"\n",
    "\n",
    "    SOURCE = \"SOURCE\"\n",
    "    SINK = \"SINK\"\n",
    "    THINGNODE = \"THINGNODE\"\n",
    "\n",
    "    \n",
    "class ExternalType(str, Enum):\n",
    "    METADATA_INT = \"metadata(int)\"\n",
    "    METADATA_FLOAT = \"metadata(float)\"\n",
    "    METADATA_STR = \"metadata(str)\"\n",
    "    METADATA_BOOLEAN = \"metadata(bool)\"\n",
    "    METADATA_ANY = \"metadata(any)\"\n",
    "\n",
    "    TIMESERIES_INT = \"timeseries(int)\"\n",
    "    TIMESERIES_FLOAT = \"timeseries(float)\"\n",
    "    TIMESERIES_STR = \"timeseries(str)\"\n",
    "    TIMESERIES_BOOLEAN = \"timeseries(bool)\"\n",
    "    TIMESERIES_ANY = \"timeseries(any)\"\n",
    "\n",
    "    SERIES_INT = \"series(int)\"\n",
    "    SERIES_FLOAT = \"series(float)\"\n",
    "    SERIES_STR = \"series(str)\"\n",
    "    SERIES_BOOLEAN = \"series(bool)\"\n",
    "    SERIES_ANY = \"series(any)\"\n",
    "\n",
    "    DATAFRAME = \"dataframe\"\n",
    "    \n",
    "\n",
    "class InputWiring(BaseModel):\n",
    "    workflow_input_name: str = Field(..., alias=\"workflow_input_name\")\n",
    "    adapter_id: Union[int, str] = Field(..., alias=\"adapter_id\")\n",
    "\n",
    "    ref_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Id referencing the source in external systems.\"\n",
    "            \" Not necessary for direct provisioning.\"\n",
    "        ),\n",
    "    )\n",
    "    ref_id_type: Optional[RefIdType] = Field(\n",
    "        None,\n",
    "        description=\"Required if type is specified and is a metadata type. \"\n",
    "        \"Then describes to what kind of object in the tree the metadatum is attached. \"\n",
    "        \"Must then be one of \"\n",
    "        \", \".join(['\"' + x.value + '\"' for x in list(RefIdType)]),\n",
    "    )\n",
    "    ref_key: Optional[str] = None\n",
    "    type: Optional[ExternalType] = Field(\n",
    "        None,\n",
    "        description=\"Type of data. If present then must be one of \"\n",
    "        + \", \".join(['\"' + x.value + '\"' for x in list(ExternalType)]),\n",
    "    )\n",
    "    filters: dict = {}\n",
    "        \n",
    "        \n",
    "class OutputWiring(BaseModel):\n",
    "    workflow_output_name: str = Field(..., alias=\"workflow_output_name\")\n",
    "    adapter_id: Union[int, str] = Field(..., alias=\"adapter_id\")\n",
    "    ref_id: Optional[str] = Field(\n",
    "        None,\n",
    "        description=(\n",
    "            \"Id referencing the sink in external systems.\"\n",
    "            \" Not necessary for direct provisioning.\"\n",
    "        ),\n",
    "    )\n",
    "    ref_id_type: Optional[RefIdType] = Field(\n",
    "        None,\n",
    "        description=\"Required if type is specified and is a metadata type. \"\n",
    "        \"Then describes to what kind of object in the tree the metadatum is attached. \"\n",
    "        \"Must then be one of \"\n",
    "        \", \".join(['\"' + x.value + '\"' for x in list(RefIdType)]),\n",
    "    )\n",
    "    ref_key: Optional[str] = Field(\n",
    "        None,\n",
    "        description=\"Required if type is specified and is a metadata type. \"\n",
    "        \"Then is the key of the metdatum.\",\n",
    "    )\n",
    "    type: Optional[ExternalType] = Field(\n",
    "        None,\n",
    "        description=\"Type of data. If present then must be one of \"\n",
    "        + \", \".join(['\"' + x.value + '\"' for x in list(ExternalType)]),\n",
    "    )\n",
    "        \n",
    "        \n",
    "class WorkflowWiring(BaseModel):\n",
    "    input_wirings: List[InputWiring] = []\n",
    "    output_wirings: List[OutputWiring] = []\n",
    "        \n",
    "\n",
    "class TransformationRevision(BaseModel):\n",
    "    \"\"\"Either a component revision or a workflow revision\n",
    "\n",
    "    Both can be instantiated as an operator in a workflow revision\n",
    "    (yes, workflow in workflow in workflow... is possible) and are therefore\n",
    "    able to transform input data to output result data.\n",
    "\n",
    "    Note that there is no actual component or workflow entity, only revisions. Revisions are tied\n",
    "    together via the group id, and otherwise do not need to have anything in common, i.e. their\n",
    "    name and their interface etc. can differ completely.\n",
    "\n",
    "    Revisions with state RELEASED are what makes execution reproducible - they cannot be edited any\n",
    "    more and only they can be instantiated as operators.\n",
    "\n",
    "    Additionally RELEASED revisions cannot be deleted, but their state can be changed to\n",
    "    DISABLED. DISABLED revisions cannot be instantiated as new operators anymore but existing\n",
    "    operators from them still work (for reproducibility). Note that in the Frontend the DISABLED\n",
    "    state is called \"DEPRECATED\". The frontend then allows to replace deprecated operators by other\n",
    "    (possibly newer) released revisions from the the same revision group (i.e. same group id).\n",
    "    \"\"\"\n",
    "\n",
    "    id: UUID\n",
    "    revision_group_id: UUID\n",
    "    name: str\n",
    "    description: str = \"\"\n",
    "    category: str = Field(\n",
    "        \"Other\",\n",
    "        description='Category in which this is classified, i.e. the \"drawer\" in the User Interface',\n",
    "    )\n",
    "    version_tag: str\n",
    "    released_timestamp: Optional[datetime.datetime] = Field(\n",
    "        None,\n",
    "        description=\"If the revision is RELEASED then this should be release timestamp\",\n",
    "    )\n",
    "\n",
    "    disabled_timestamp: Optional[datetime.datetime] = Field(\n",
    "        None,\n",
    "        description=\"If the revision is DISABLED then this should be disable/deprecation timestamp\",\n",
    "    )\n",
    "    state: State = Field(\n",
    "        ...,\n",
    "        description=\"one of \" + \", \".join(['\"' + x.value + '\"' for x in list(State)]),\n",
    "    )\n",
    "    type: Type = Field(\n",
    "        ...,\n",
    "        description=\"one of \" + \", \".join(['\"' + x.value + '\"' for x in list(Type)]),\n",
    "    )\n",
    "\n",
    "    documentation: str = Field(\n",
    "        (\n",
    "            \"\\n\"\n",
    "            \"# New Component/Workflow\\n\"\n",
    "            \"## Description\\n\"\n",
    "            \"## Inputs\\n\"\n",
    "            \"## Outputs\\n\"\n",
    "            \"## Details\\n\"\n",
    "            \"## Examples\\n\"\n",
    "        ),\n",
    "        description=\"Documentation in markdown format.\",\n",
    "    )\n",
    "    content: Union[str,dict]\n",
    "\n",
    "    io_interface: IOInterface = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"In case of type WORKFLOW determined from content. \"\n",
    "            \"To change from state DRAFT to state RELEASED all inputs and outputs must have names.\"\n",
    "        ),\n",
    "    )\n",
    "        \n",
    "    test_wiring: WorkflowWiring = Field(\n",
    "        ...,\n",
    "        description=(\n",
    "            \"The input and output wirings must match \"\n",
    "            \"the inputs and outputs of the io_interface\"\n",
    "        ),\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9af0d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComponentInfo(BaseModel):\n",
    "    \"\"\"Provide meta-information about component.\n",
    "\n",
    "    Used as input for code generation to include meta-information about the component in the code.\n",
    "\n",
    "    This additional information makes it possible to recover the underlying transformation revision\n",
    "    object from the code.\n",
    "    \"\"\"\n",
    "\n",
    "    input_types_by_name: Dict[str, DataType]\n",
    "    output_types_by_name: Dict[str, DataType]\n",
    "    id: UUID = Field(default_factory=uuid4)\n",
    "    revision_group_id: UUID = Field(default_factory=uuid4)\n",
    "    name: NonEmptyValidStr\n",
    "    category: NonEmptyValidStr\n",
    "    description: ValidStr\n",
    "    version_tag: ShortNonEmptyValidStr\n",
    "    is_coroutine: bool = False\n",
    "        \n",
    "    @classmethod\n",
    "    def from_tr(cls, tr: TransformationRevision) -> \"ComponentInfo\":\n",
    "        return ComponentInfo(\n",
    "            input_types_by_name={io.name: io.data_type for io in tr.io_interface.inputs},\n",
    "            output_types_by_name={io.name: io.data_type for io in tr.io_interface.outputs},\n",
    "            id=tr.id,\n",
    "            revision_group_id=tr.revision_group_id,\n",
    "            name=tr.name,\n",
    "            category=tr.category,\n",
    "            description=tr.description,\n",
    "            version_tag=tr.version_tag,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9befd236",
   "metadata": {},
   "outputs": [],
   "source": [
    "imports_template: str = \"\"\"\\\n",
    "from hetdesrun.component.registration import register\n",
    "from hetdesrun.datatypes import DataType\n",
    "# add your own imports here, e.g.\n",
    "#     import pandas as pd\n",
    "#     import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "function_definition_template: str = \"\"\"\\\n",
    "# ***** DO NOT EDIT LINES BELOW *****\n",
    "# These lines may be overwritten if component details or inputs/outputs change.\n",
    "@register(\n",
    "    inputs={input_dict_content},\n",
    "    outputs={output_dict_content},\n",
    "    name={name},\n",
    "    description={description},\n",
    "    category={category},\n",
    "    id={id},\n",
    "    revision_group_id={revision_group_id},\n",
    "    version_tag={version_tag}\n",
    ")\n",
    "{main_func_declaration_start} main({params_list}):\n",
    "    # entrypoint function for this component\n",
    "    # ***** DO NOT EDIT LINES ABOVE *****\\\n",
    "\"\"\"\n",
    "\n",
    "function_body_template: str = \"\"\"\\\n",
    "    # write your function code here.\n",
    "    pass\\\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def generate_function_header(component_info: ComponentInfo) -> str:\n",
    "    \"\"\"Generate entrypoint function header from the inputs and their types\"\"\"\n",
    "    param_list_str = (\n",
    "        \"\"\n",
    "        if len(component_info.input_types_by_name.keys()) == 0\n",
    "        else \"*, \" + \", \".join(component_info.input_types_by_name.keys())\n",
    "    )\n",
    "\n",
    "    main_func_declaration_start = \"async def\" if component_info.is_coroutine else \"def\"\n",
    "\n",
    "    return function_definition_template.format(\n",
    "        input_dict_content=\"{\"\n",
    "        + \", \".join(\n",
    "            [\n",
    "                '\"' + key + '\": DataType.' + value.name\n",
    "                for key, value in component_info.input_types_by_name.items()\n",
    "            ]\n",
    "        )\n",
    "        + \"}\",\n",
    "        output_dict_content=\"{\"\n",
    "        + \", \".join(\n",
    "            [\n",
    "                '\"' + key + '\": DataType.' + value.name\n",
    "                for key, value in component_info.output_types_by_name.items()\n",
    "            ]\n",
    "        )\n",
    "        + \"}\",\n",
    "        name='\"' + component_info.name + '\"',\n",
    "        description='\"' + component_info.description + '\"',\n",
    "        category='\"' + component_info.category + '\"',\n",
    "        id='\"' + str(component_info.id) + '\"',\n",
    "        revision_group_id='\"' + str(component_info.revision_group_id) + '\"',\n",
    "        version_tag='\"' + component_info.version_tag + '\"',\n",
    "        params_list=param_list_str,\n",
    "        main_func_declaration_start=main_func_declaration_start,\n",
    "    )\n",
    "\n",
    "\n",
    "def generate_complete_component_module(component_info: ComponentInfo) -> str:\n",
    "    return (\n",
    "        imports_template\n",
    "        + \"\\n\"\n",
    "        + generate_function_header(component_info)\n",
    "        + \"\\n\"\n",
    "        + function_body_template\n",
    "    )\n",
    "\n",
    "\n",
    "def update_code(\n",
    "    existing_code: Optional[str],\n",
    "    component_info: ComponentInfo,\n",
    ") -> str:\n",
    "    \"\"\"Generate and update component code\n",
    "\n",
    "    Tries to replace the existing_code with a new version with the correct function definition\n",
    "    from input_type_dict and output_type_dict.\n",
    "    If no existing_code is provided it completely generates a component module code stub\n",
    "    including necessary imports.\n",
    "\n",
    "    The updating process is rather naive: It does not rely on parsing the abstract syntax tree.\n",
    "    It only uses basic String methods and does not try to handle every case. It therefore may\n",
    "    undesirably replace user code in some cases.\n",
    "    \"\"\"\n",
    "    if existing_code is None or existing_code == \"\":\n",
    "        return generate_complete_component_module(component_info)\n",
    "\n",
    "    new_function_header = generate_function_header(component_info)\n",
    "\n",
    "    try:\n",
    "        start, remaining = existing_code.split(\n",
    "            \"# ***** DO NOT EDIT LINES BELOW *****\", 1\n",
    "        )\n",
    "    except ValueError:\n",
    "        # Cannot find func def, therefore append it (assuming necessary imports are present):\n",
    "        # This may secretely add a second main entrypoint function!\n",
    "        return (\n",
    "            existing_code + \"\\n\\n\" + new_function_header + \"\\n\" + function_body_template\n",
    "        )\n",
    "\n",
    "    if \"    # ***** DO NOT EDIT LINES ABOVE *****\" not in remaining:\n",
    "        # Cannot find end of function definition.\n",
    "        # Therefore replace all code starting from the detected beginning of the function\n",
    "        # definition. This deletes all user code below!\n",
    "        return start + new_function_header + \"\\n\" + function_body_template\n",
    "\n",
    "    # we now are quite sure that we find a complete existing function definition\n",
    "\n",
    "    # pylint: disable=unused-variable\n",
    "    old_func_def, end = remaining.split(\"    # ***** DO NOT EDIT LINES ABOVE *****\", 1)\n",
    "\n",
    "    old_func_def_lines = old_func_def.split(\"\\n\")\n",
    "    use_async_def = (len(old_func_def_lines) >= 3) and old_func_def_lines[\n",
    "        -3\n",
    "    ].startswith(\"async def\")\n",
    "    component_info.is_coroutine = use_async_def\n",
    "\n",
    "    new_function_header = generate_function_header(component_info)\n",
    "\n",
    "    return start + new_function_header + end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0080799e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_input_wiring(tr: TransformationRevision, input_json: dict) -> None:\n",
    "    wf_input_names = sorted([wf_input.name for wf_input in tr.io_interface.inputs])\n",
    "    input_json_names = sorted([input_name for input_name in input_json])\n",
    "    if input_json_names != wf_input_names:\n",
    "        raise ValueError(tr.category+\", \"+tr.name+\": \"+str(input_json_names)+\"!=\"+str(wf_input_names))\n",
    "    input_wirings = []\n",
    "    for wf_input in tr.io_interface.inputs:\n",
    "        input_wirings.append(\n",
    "            InputWiring(\n",
    "                workflow_input_name = wf_input.name,\n",
    "                adapter_id = \"direct_provisioning\",\n",
    "                filters = {\"value\": input_json[wf_input.name]}\n",
    "            )\n",
    "        )\n",
    "    tr.test_wiring.input_wirings = input_wirings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91ea1017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_only_output_wiring(tr: TransformationRevision) -> None:\n",
    "    output_wirings = []\n",
    "    for output_wiring in tr.test_wiring.output_wirings:\n",
    "        if output_wiring.adapter_id == \"direct_provisioning\":\n",
    "            print(\"removed output wiring\")\n",
    "        else:\n",
    "            output_wirings.append(output_wiring)\n",
    "            print(\"keep output wiring: \"+str(output_wiring))\n",
    "    if len(tr.test_wiring.output_wirings) == 0:\n",
    "        print(\"no output wiring present\")\n",
    "    tr.test_wiring.output_wirings = output_wirings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cf82309e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./transformations/components/time-length-operations/time-gaps_100_7b18532a-8e26-7b30-5053-6f5f056be3d4.json\n",
      "./transformations/components/time-length-operations/shift-datetime-index_100_64d61740-f520-492f-ffa7-485916fc973c.json\n",
      "./transformations/components/time-length-operations/linear-interpolation-numeric-index_100_1d53dedc-9e4a-1ccc-4dfb-3e5059f89db8.json\n",
      "./transformations/components/time-length-operations/shift-values_100_66811a16-65e6-ad80-ce1d-669f97d06d16.json\n",
      "./transformations/components/time-length-operations/resample-numeric-index-using-mean_100_015d7a72-f9c3-8a14-dde8-3aa59b2e9f10.json\n",
      "./transformations/components/time-length-operations/count-level-crossings_100_8b8046ec-0817-e314-936c-08e8c5116ef5.json\n",
      "./transformations/components/time-length-operations/linear-interpolation-datetime-index_100_0362dc9d-9861-b2c2-e26b-2a42909346bf.json\n",
      "./transformations/components/time-length-operations/resample-datetime-index-using-mean_100_d48ce6ad-05ab-8bc1-fb79-c1960966f595.json\n",
      "./transformations/components/arithmetic/consecutive-differences_100_ce801dcb-8ce1-14ad-029d-a14796dcac92.json\n",
      "./transformations/components/arithmetic/e_100_13d3376a-9c08-d78f-8ad4-6d24fef504ca.json\n",
      "./transformations/components/arithmetic/cumulative-sum_100_d2cc4c0d-303e-b0ad-fdba-73392e890b30.json\n",
      "./transformations/components/arithmetic/modulo_100_ebb5b2d1-7c25-94dd-ca81-6a9e5b21bc2f.json\n",
      "./transformations/components/arithmetic/power_100_d24f40ae-4dfb-248f-6461-e67be3e5de8a.json\n",
      "./transformations/components/arithmetic/exp_100_0da30127-b4d1-5e0d-2621-2c59b891c9b0.json\n",
      "./transformations/components/arithmetic/log-to-base_100_cd804f5d-76ea-1f8b-6adc-b4c4a78acaf4.json\n",
      "./transformations/components/arithmetic/sum-columns_100_619cbd38-26b4-3d5e-14a0-721224b13bc7.json\n",
      "./transformations/components/arithmetic/derivate_100_84bcdf4c-a068-3679-0cec-78bd6fcd3b48.json\n",
      "./transformations/components/arithmetic/nth-root_100_11152e31-cf25-4280-2b28-220319277011.json\n",
      "./transformations/components/arithmetic/ln_100_9f3ebd8c-92cf-deb1-09e9-d67ba16e9754.json\n",
      "./transformations/components/arithmetic/sqrt_100_40a03a56-5e3d-2695-07e4-9bcf0b1c3a39.json\n",
      "./transformations/components/arithmetic/pi_100_84337854-360a-bbc3-203c-f795d549076d.json\n",
      "./transformations/components/arithmetic/integrate_100_dd73bac2-cd9d-61c5-0aec-9dec6f337516.json\n",
      "./transformations/components/arithmetic/sum-up-series_100_878d85a2-2cf5-235b-d260-fd94c734cec9.json\n",
      "./transformations/components/basic/greater-or-equal_100_f759e4c0-1468-0f2e-9740-41302b860193.json\n",
      "./transformations/components/basic/greater_100_e6918e9e-aaaf-6f84-175a-fc2ac03ed85d.json\n",
      "./transformations/components/basic/equality_100_9ccc8df5-5e68-46ff-bc2d-1fa82dae972c.json\n",
      "./transformations/components/basic/select-column-from-dataframe_100_a652465e-b479-1cc9-bf82-41f7cedc4963.json\n",
      "./transformations/components/basic/restrict-to-time-interval_100_bf469c0a-d17c-ca6f-59ac-9838b2ff67ac.json\n",
      "./transformations/components/basic/smaller-or-equal_100_8a7e43b9-ce04-796e-6b73-5ce67547122a.json\n",
      "./transformations/components/basic/inequality_100_4ec3ef23-6bea-872d-1905-c9c6d06dddef.json\n",
      "./transformations/components/basic/filter_100_18260aab-bdd6-af5c-cac1-7bafde85188f.json\n",
      "./transformations/components/basic/first-datetime-index_100_c7dbb92b-4a4c-c6d2-6665-5ee7d4eeab91.json\n",
      "./transformations/components/basic/smaller_100_9f33cbbc-3935-e9f3-a682-99579e96a4d0.json\n",
      "./transformations/components/basic/last-datetime-index_100_c8e3bc64-b214-6486-31db-92a8888d8991.json\n",
      "./transformations/components/data-sources/get-r-dataset_100_80f4f916-4568-29bb-3f94-b487b0612232.json\n",
      "./transformations/components/data-sources/load-object_100_eb8e8d6b-ba7d-dc88-14dc-6839a471d5e0.json\n",
      "./transformations/components/models/predict-sklearn-trained-model_100_41e8bf16-0a16-6021-33c9-88c2f8336df8.json\n",
      "./transformations/components/models/decision-function-sklearn-trained-model_100_f35c4918-0a5d-d29c-f3fa-6cfcd425b0f7.json\n",
      "./transformations/components/data-quality/apply-substitution-timeseries_100_e1475799-eeab-8a18-97bf-69aa09d86a4a.json\n",
      "./transformations/components/anomaly-detection/isolation-forest_100_cdec1d55-5bb6-8e8d-4571-fbc0ebf5a354.json\n",
      "./transformations/components/anomaly-detection/simple-volatility-score_100_0c3c74d0-89b6-1948-fedd-753eaa47ca0e.json\n",
      "./transformations/components/anomaly-detection/alerts-from-score_100_38f168ef-cb06-d89c-79b3-0cd823f32e9d.json\n",
      "./transformations/components/trigonometric/sine_100_2cc88d07-b151-dc5b-d4c4-cfd95a043de3.json\n",
      "./transformations/components/trigonometric/cosine_100_1a83d0bb-2321-fd1a-8db4-22320b6eeb1c.json\n",
      "./transformations/components/trigonometric/arcustangent_100_8b974f17-5055-80f2-64f5-96c6eff93a35.json\n",
      "./transformations/components/trigonometric/arcussine_100_487008dc-1476-139c-5392-d5d0de1e6505.json\n",
      "./transformations/components/trigonometric/tangent_100_38eb0c5d-6182-0be2-3058-9b5bddc7842d.json\n",
      "./transformations/components/trigonometric/arcuscosine_100_ba0783de-93ab-0eb2-87fd-a5e09aff9d87.json\n",
      "./transformations/components/visualization/timeseries-plot-with-multiple-movable-x-and-y-axes_100_4e5115a2-2a45-4156-6f54-ff66c176daea.json\n",
      "./transformations/components/visualization/correlation-matrix-heatmap-plot_100_8debf23e-54e3-5fa1-bb57-6d41058c66b7.json\n",
      "./transformations/components/visualization/timeseries-dataframe-plot-with-multiple-y-axes_100_58e793bf-1aa7-316c-bc8a-f34a435fc8f0.json\n",
      "./transformations/components/visualization/contour-plot_100_f7530499-51b2-dd01-0d21-c24ee6f8c37e.json\n",
      "./transformations/components/visualization/timeseries-substitution-plot_100_3160c5a1-0cfb-7396-739a-a106c2a3e130.json\n",
      "./transformations/components/visualization/simple-scatter-map-plot_100_dc909fa2-93fa-3205-e31d-b05f944cbd29.json\n",
      "./transformations/components/visualization/dataframe-plot-with-multiple-x-and-y-axes_100_db80c471-924f-af19-e97b-06de42af6a30.json\n",
      "./transformations/components/visualization/2d-scatter-plot-colored-by-other-series_100_216f03cb-eec8-1907-f980-1df6abc2fb5b.json\n",
      "./transformations/components/visualization/compare-two-timeseries-plot_100_a432923f-4718-44ae-3c9c-9832e68724bb.json\n",
      "./transformations/components/visualization/univariate-linear-rul-regression-result-plot_100_9c3f88ce-1311-241e-18b7-acf7d3f5a051.json\n",
      "./transformations/components/visualization/timeseries-and-alerts-plot_100_95c006e4-5050-7722-6717-d1c6be2ba890.json\n",
      "./transformations/components/visualization/timeseries-interval-boxplots_100_56c937d5-37df-c70f-2113-808ef4a6d9ba.json\n",
      "./transformations/components/visualization/display-table_100_e0320729-10df-8979-4444-feb6fe7adc82.json\n",
      "./transformations/components/visualization/two-timeseries-with-two-y-axes-plot_100_5dc42708-34fd-ab82-bf2c-307fd66ad749.json\n",
      "./transformations/components/visualization/compare-timeshifted-timeseries_100_daed7280-7013-3be1-41c0-65e4628e0e1d.json\n",
      "./transformations/components/visualization/vertical-bar-plot_100_9f55f116-f22a-c94b-42b4-1f7c184da3bf.json\n",
      "./transformations/components/visualization/timeseries-dataframe-plot_100_16d6e587-25ea-d0df-f514-da9fef66ad80.json\n",
      "./transformations/components/visualization/2d-scatter-plot-colored-by-index_100_a408a19b-70fd-5a16-958c-193d678c2c2b.json\n",
      "./transformations/components/visualization/2d-grid-generator_100_096c6181-4ba5-0ee7-361a-3c32eee8c0c2.json\n",
      "./transformations/components/visualization/single-timeseries-plot_100_8fba9b51-a0f1-6c6c-a6d4-e224103b819c.json\n",
      "./transformations/components/visualization/pie-chart-plot_100_3b2fe728-5f36-64be-3963-df83918ff8a9.json\n",
      "./transformations/components/remaining-useful-life/univariate-linear-rul-regression_100_8d61a267-3a71-51cd-2817-48c320469d6b.json\n",
      "./transformations/components/basic-arithmetic/divide_100_6d510037-229e-8e85-56f3-4a3797fdf315.json\n",
      "./transformations/components/basic-arithmetic/abs_100_ea4a196f-5d94-d3cf-02e8-8c750414fc89.json\n",
      "./transformations/components/basic-arithmetic/substract_100_10d27d69-e999-6654-3cef-427672aeb0fa.json\n",
      "./transformations/components/basic-arithmetic/multiply_100_0438da97-f524-4a68-28c9-a88c81aa2c63.json\n",
      "./transformations/components/basic-arithmetic/signum_100_24f115a8-45ad-21f2-c6ce-8edfc28f3b3f.json\n",
      "./transformations/components/basic-arithmetic/round_100_50220962-16c0-c94f-8f0a-1e57d76e6878.json\n",
      "./transformations/components/basic-arithmetic/add_100_2abf72f6-68c9-7398-7175-165d31b3ced7.json\n",
      "./transformations/components/connectors/dataframe-to-series_100_152bc7df-708c-2ecb-1d5d-b69483fdd275.json\n",
      "./transformations/components/connectors/pass-through-float_100_2f511674-f766-748d-2de3-ad5e62e10a1a.json\n",
      "./transformations/components/connectors/pass-through_100_1946d5f8-44a8-724c-176f-16f3e49963af.json\n",
      "./transformations/components/connectors/combine-as-named-column-into-dataframe_100_0d08af64-3f34-cddc-354b-d6a26c3f1aab.json\n",
      "./transformations/components/connectors/pass-through-series_100_bfa27afc-dea8-b8aa-4b15-94402f0739b6.json\n",
      "./transformations/components/connectors/timeseries-dataframe_100_d71a0cef-1d56-818f-a1a5-dd6bb6d50399.json\n",
      "./transformations/components/connectors/combine-into-dataframe_100_68f91351-a1f5-9959-414a-2c72003f3226.json\n",
      "./transformations/components/connectors/pass-through-string_100_2b1b474f-ddf5-1f4d-fec4-17ef9122112b.json\n",
      "./transformations/components/connectors/pass-through-dataframe_100_7a1a818f-fa89-6062-1e0e-fc80539bbe0a.json\n",
      "./transformations/components/connectors/name-series_100_a4064897-66d3-9601-328e-5ae9036665c5.json\n",
      "./transformations/components/connectors/merge-dataframes-on-single-column_100_a573c94f-3039-1193-b068-bc496620c6ed.json\n",
      "./transformations/components/connectors/pass-through-integer_100_57eea09f-d28e-89af-4e81-2027697a3f0f.json\n",
      "./transformations/components/connectors/pass-through-boolean_100_8ea34104-2dd1-b4dc-8fd4-ed07bb967060.json\n",
      "./transformations/components/connectors/forget_100_d1fb4ae5-ef27-26b8-7a58-40b7cd8412e7.json\n",
      "./transformations/components/connectors/convert-series-to-dataframe_100_2f8c3864-8d45-5d68-c73f-229ef43bf944.json\n",
      "./transformations/components/data-sinks/store-object_100_26d99461-38a9-5e92-df4f-d0fd2752879e.json\n",
      "./transformations/components/index-operations/restrict-to-common-index_100_ac86c25c-a510-e46e-ff3a-f9bbb4c26a24.json\n",
      "./transformations/components/index-operations/timeshifted-value-table_100_e4541a9d-7b3e-3dd6-869d-eff30ad997c3.json\n",
      "./transformations/components/index-operations/sort-by-index_100_7f315341-d095-1f4b-b72c-e85dc3d7c508.json\n",
      "./transformations/components/regression/linear-regression_100_10ab5fc1-9654-8a46-1c36-03660b4a2681.json\n",
      "./transformations/components/regression/linear-regression-two-series_100_ff182e84-913d-e799-5722-98a5d2e3ad09.json\n",
      "./transformations/components/physics/time-to-length_100_517fb2a7-ec6a-eced-c2ea-eb6dc5e76b0c.json\n",
      "./transformations/components/filters/mavg-outlier-filter_100_11b9c01e-8e32-25a9-9625-97a5654230be.json\n",
      "./transformations/components/filters/drop-duplicates_100_72570287-ecb6-4c74-3902-ace451662138.json\n",
      "./transformations/components/filters/cut-values-below-limit_100_07f979e0-11bd-f91a-1a8f-52b4ef883d74.json\n",
      "./transformations/components/filters/highpass-filter_100_417d44a2-1701-2e5b-bee8-7ce1a4dc1d0e.json\n",
      "./transformations/components/filters/drop-nan-values_100_e8b1d655-803c-e79f-5c15-62aec3a4c27d.json\n",
      "./transformations/components/filters/cut-values-above-limit_100_e3323561-276e-d4a8-8417-badedbbd3c98.json\n",
      "./transformations/components/filters/mavg-smoothing_100_41f4c453-e4e7-f07d-df77-c89cb42cb3ac.json\n",
      "./transformations/components/filters/reduce-data-set-by-leaving-out-values_100_0a871bb6-b59c-e94d-40fd-a6673d1713c7.json\n",
      "./transformations/components/filters/lowpass-filter_100_a4a8cfa7-3b18-dc8d-2985-9a8be889686a.json\n",
      "./transformations/components/statistic/moving-median-number_100_c9736810-73d8-b109-3822-96a5bf0a6d1c.json\n",
      "./transformations/components/statistic/average_100_bbf3e562-439a-9662-616f-969bf79d57a2.json\n",
      "./transformations/components/statistic/moving-maximum-time_100_037887de-bbee-caeb-f0bd-7060d59f60e9.json\n",
      "./transformations/components/statistic/moving-average-time_100_a2ba0da0-5a9a-60e9-6af5-e07917988021.json\n",
      "./transformations/components/statistic/standard-scale_100_6c4ce4d5-e73f-210e-48a8-230c8e5088ef.json\n",
      "./transformations/components/statistic/moving-standard-deviation-number_100_acfd3d99-0a6c-97ae-7bcf-de08ea9ce4ee.json\n",
      "./transformations/components/statistic/maximum_100_d72939c2-1b0c-065e-556a-c9974c179c0f.json\n",
      "./transformations/components/statistic/moving-minimum-number_100_e79f021a-93a8-d55b-1032-19d91d78fd51.json\n",
      "./transformations/components/statistic/moving-maximum-number_100_468f917b-7b99-9394-d600-50ee05237041.json\n",
      "./transformations/components/statistic/minimum_100_375819f5-deb3-0d5f-8661-22d202b39c54.json\n",
      "./transformations/components/statistic/standard-deviation_100_462e4cd5-1772-a925-6d26-8d33011111cd.json\n",
      "./transformations/components/statistic/moving-median-time_100_1feea93c-a6e7-4fec-c01c-6f30037f8cca.json\n",
      "./transformations/components/statistic/moving-average-number_100_c9c8eb62-a694-3108-1c64-957bdd514c2b.json\n",
      "./transformations/components/statistic/moving-standard-deviation-time_100_5eb8ca16-bbc7-94b1-3d82-6f074cd63456.json\n",
      "./transformations/components/statistic/moving-minimum-time_100_33d7c458-762c-7555-7a20-26ef0708bc28.json\n",
      "./transformations/components/statistic/median_100_dc9dcd3d-88a0-539c-c5d9-bb52c0eded33.json\n",
      "./transformations/workflows/connectors/combine-two-series-into-dataframe_100_09b29726-4373-4652-82c8-7aa3e3f91676.json\n",
      "./transformations/workflows/connectors/combine-two-series-as-named-columns-into-dataframe_100_45f4f0c1-3fda-4c3b-8187-c590610e6975.json\n",
      "./transformations/workflows/examples/univariate-linear-rul-regression-example_100_806df1b9-2fc8-4463-943f-3d258c569663.json\n",
      "./transformations/workflows/examples/visualization-demo_100_7ccb7acb-4779-4931-b436-2d4d5172607b.json\n",
      "./transformations/workflows/examples/linear-rul-from-last-positive-step_100_3d504361-e351-4d52-8734-391aa47e8f24.json\n",
      "./transformations/workflows/examples/data-from-last-positive-step_100_2cbb87e7-ea99-4404-abe1-be550f22763f.json\n",
      "./transformations/workflows/examples/iso-forest-example_100_67c14cf2-cd4e-410e-9aca-6664273ccc3f.json\n",
      "./transformations/workflows/examples/volatility-detection-example_100_79ce1eb1-3ef8-4c74-9114-c856fd88dc89.json\n"
     ]
    }
   ],
   "source": [
    "json_files = []\n",
    "for root, _, files in os.walk(\"./transformations\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            json_files.append(os.path.join(root, file))\n",
    "            print(json_files[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f336c162",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./transformations/components/time-length-operations/time-gaps_100_7b18532a-8e26-7b30-5053-6f5f056be3d4.json\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType  # add your own imports here\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Series},\n",
      "    outputs={\"gap_sizes\": DataType.Series},\n",
      "    name=\"Time Gaps\",\n",
      "    description=\"Calculates the sizes of time gaps\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"7b18532a-8e26-7b30-5053-6f5f056be3d4\",\n",
      "    revision_group_id=\"7b18532a-8e26-7b30-5053-6f5f056be3d4\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...             [1,2,3], \n",
      "    ...             index = pd.to_datetime([\n",
      "    ...                 \"2019-08-01T00:00:00\",\n",
      "    ...                 \"2019-08-01T00:00:20\",\n",
      "    ...                 \"2019-08-01T00:00:50\"\n",
      "    ...             ])\n",
      "    ...     )\n",
      "    ... )[\"gap_sizes\"]\n",
      "    2019-08-01 00:00:20    20.0\n",
      "    2019-08-01 00:00:50    30.0\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "    if not len(data) >= 2:\n",
      "        raise ValueError(f\"length of data must be greater than 1, it is {len(data)}\")\n",
      "    return {\n",
      "        \"gap_sizes\": pd.Series(\n",
      "            (data.index.values[1:] - data.index.values[:-1]) / np.timedelta64(1, \"s\"),\n",
      "            index=data.index.values[1:],\n",
      "        )\n",
      "    }\n",
      "\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/shift-datetime-index_100_64d61740-f520-492f-ffa7-485916fc973c.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any, \"frequency\": DataType.String, \"periods\": DataType.Integer},\n",
      "    outputs={\"shifted\": DataType.Any},\n",
      "    name=\"Shift Datetime Index\",\n",
      "    description=\"Shift index by desired frequency\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"64d61740-f520-492f-ffa7-485916fc973c\",\n",
      "    revision_group_id=\"64d61740-f520-492f-ffa7-485916fc973c\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, frequency, periods):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data=pd.Series(\n",
      "    ...             [10.0, 22.0, 18.0, 2.0],   \n",
      "    ...             index=pd.to_datetime([\"2019-08-01T15:20:10\", \"2019-08-01T15:20:11\", \"2019-08-01T15:20:14\", \"2019-08-01T15:20:16\"])\n",
      "    ...     ),\n",
      "    ...     frequency = \"s\",\n",
      "    ...     periods = -4\n",
      "    ... )[\"shifted\"]\n",
      "    2019-08-01 15:20:06    10.0\n",
      "    2019-08-01 15:20:07    22.0\n",
      "    2019-08-01 15:20:10    18.0\n",
      "    2019-08-01 15:20:12     2.0\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "    shifted = data.copy()\n",
      "    shifted.index = shifted.index.shift(periods=periods, freq=frequency)\n",
      "    return {\"shifted\": shifted}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/linear-interpolation-numeric-index_100_1d53dedc-9e4a-1ccc-4dfb-3e5059f89db8.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any, \"d\": DataType.Integer},\n",
      "    outputs={\"interpolation\": DataType.Any},\n",
      "    name=\"Linear Interpolation numeric index\",\n",
      "    description=\"Calculates the linear interpolation for some distance\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"1d53dedc-9e4a-1ccc-4dfb-3e5059f89db8\",\n",
      "    revision_group_id=\"1d53dedc-9e4a-1ccc-4dfb-3e5059f89db8\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, d):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...         [1.2, 7.2, 2.8, 4.8, 10.8],\n",
      "    ...         index = [2, 3, 5, 6, 9]\n",
      "    ...     ),\n",
      "    ...     d = 2\n",
      "    ... )[\"interpolation\"]\n",
      "    2    1.2\n",
      "    4    5.0\n",
      "    6    4.8\n",
      "    8    8.8\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your code here.\n",
      "\n",
      "    if data.empty:\n",
      "        return {\"interpolation\": data}\n",
      "    data_reindex = data.reindex(\n",
      "        pd.RangeIndex(data.index[0], data.index[-1], d).union(data.index)\n",
      "    )\n",
      "    data_reindex = data_reindex.interpolate(method=\"index\")\n",
      "    return {\n",
      "        \"interpolation\": data_reindex.reindex(\n",
      "            pd.RangeIndex(data.index[0], data.index[-1] + 1, d)\n",
      "        )\n",
      "    }\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/shift-values_100_66811a16-65e6-ad80-ce1d-669f97d06d16.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any, \"periods\": DataType.Integer},\n",
      "    outputs={\"shifted\": DataType.Any},\n",
      "    name=\"Shift Values\",\n",
      "    description=\"Shift index by desired number of periods\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"66811a16-65e6-ad80-ce1d-669f97d06d16\",\n",
      "    revision_group_id=\"66811a16-65e6-ad80-ce1d-669f97d06d16\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, periods):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(data = pd.Series([1,4,11,8]), periods = 2)[\"shifted\"]\n",
      "    0    NaN\n",
      "    1    NaN\n",
      "    2    1.0\n",
      "    3    4.0\n",
      "    dtype: float64\n",
      "    >>> main(\n",
      "    ...     data=pd.Series(\n",
      "    ...             [10.0, 22.0, 18.0, 2.0],   \n",
      "    ...             index=pd.to_datetime([\"2019-08-01T15:20:10\", \"2019-08-01T15:20:11\", \"2019-08-01T15:20:14\", \"2019-08-01T15:20:16\"])\n",
      "    ...     ),\n",
      "    ...     periods = -1\n",
      "    ... )[\"shifted\"]\n",
      "    2019-08-01 15:20:10    22.0\n",
      "    2019-08-01 15:20:11    18.0\n",
      "    2019-08-01 15:20:14     2.0\n",
      "    2019-08-01 15:20:16     NaN\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "\n",
      "    return {\"shifted\": data.shift(periods)}\n",
      "\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/resample-numeric-index-using-mean_100_015d7a72-f9c3-8a14-dde8-3aa59b2e9f10.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any, \"d\": DataType.Integer},\n",
      "    outputs={\"resampled\": DataType.Any},\n",
      "    name=\"Resample Numeric Index using Mean\",\n",
      "    description=\"Resamples data with given distances using mean\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"015d7a72-f9c3-8a14-dde8-3aa59b2e9f10\",\n",
      "    revision_group_id=\"015d7a72-f9c3-8a14-dde8-3aa59b2e9f10\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, d):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...         [0.75, 7.25, 2.75, 5.0, 10.0],\n",
      "    ...         index = [2, 4, 5, 6, 9]\n",
      "    ...     ),\n",
      "    ...     d = 3\n",
      "    ... )[\"resampled\"]\n",
      "    2    4.0\n",
      "    5    5.0\n",
      "    8    7.5\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your code here.\n",
      "    if data.empty:\n",
      "        return {\"resampled\": data}\n",
      "    if not data.index.is_monotonic:\n",
      "        raise ValueError(\"data must be sorted by its index\")\n",
      "\n",
      "    data_reindex = data.copy()\n",
      "    data_reindex = data.reindex(\n",
      "        pd.RangeIndex(data.index[0], data.index[-1], d).union(data.index)\n",
      "    )\n",
      "    data_reindex = data_reindex.rolling(d, min_periods=1, center=True).mean()\n",
      "    return {\n",
      "        \"resampled\": data_reindex.reindex(\n",
      "            pd.RangeIndex(data.index[0], data.index[-1] + 1, d)\n",
      "        )\n",
      "    }\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/count-level-crossings_100_8b8046ec-0817-e314-936c-08e8c5116ef5.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Series, \"level\": DataType.Float, \"hysteresis\": DataType.Float, \"edge_type\": DataType.Float},\n",
      "    outputs={\"result\": DataType.Series},\n",
      "    name=\"Count level crossings\",\n",
      "    description=\"Count the level crossings of the input data\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"8b8046ec-0817-e314-936c-08e8c5116ef5\",\n",
      "    revision_group_id=\"8b8046ec-0817-e314-936c-08e8c5116ef5\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, level, hysteresis, edge_type):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(data = pd.Series([1,4,11,8,3,45,1,21,5,6]), level = 8, hysteresis = 4, edge_type = 0)[\"result\"]\n",
      "    0    0\n",
      "    1    0\n",
      "    2    1\n",
      "    3    1\n",
      "    4    2\n",
      "    5    3\n",
      "    6    4\n",
      "    7    5\n",
      "    8    6\n",
      "    9    6\n",
      "    dtype: int64\n",
      "    >>> main(\n",
      "    ...     data=pd.Series(\n",
      "    ...         {\n",
      "    ...             \"2019-08-01 15:20:10\": 10.0,\n",
      "    ...             \"2019-08-01 15:20:11\": 22.0,\n",
      "    ...             \"2019-08-01 15:20:14\": 18.0,\n",
      "    ...             \"2019-08-01 15:20:16\": 2.0,\n",
      "    ...             \"2019-08-01 15:20:18\": 11.0,\n",
      "    ...             \"2019-08-01 15:20:20\": 10.0,\n",
      "    ...             \"2019-08-01 15:20:21\": 18.0,\n",
      "    ...             \"2019-08-01 15:20:24\": 2.0,\n",
      "    ...         }\n",
      "    ...     ),\n",
      "    ...     level = 10,\n",
      "    ...     hysteresis = 1,\n",
      "    ...     edge_type = -1,\n",
      "    ... )[\"result\"]\n",
      "    2019-08-01 15:20:10    0\n",
      "    2019-08-01 15:20:11    0\n",
      "    2019-08-01 15:20:14    0\n",
      "    2019-08-01 15:20:16    1\n",
      "    2019-08-01 15:20:18    1\n",
      "    2019-08-01 15:20:20    1\n",
      "    2019-08-01 15:20:21    1\n",
      "    2019-08-01 15:20:24    2\n",
      "    dtype: int64\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "\n",
      "    if data.size < 2:\n",
      "        raise ValueError(f\"length of data must be greater than 1, it is {data.size}\")\n",
      "\n",
      "    if hysteresis < 0:\n",
      "        raise ValueError(f\"hysteresis must be non-negative, it is {hysteresis}\")\n",
      "\n",
      "    if not data.index.is_monotonic:\n",
      "        raise ValueError(\"data must be sorted by its index\")\n",
      "\n",
      "    tolerance = hysteresis / 2\n",
      "\n",
      "    crossings = (data > (level + tolerance)).astype(\"int64\") - (\n",
      "        data < (level - tolerance)\n",
      "    ).astype(\"int64\")\n",
      "    crossings = crossings[crossings != 0]\n",
      "\n",
      "    crossings.values[1:] = np.diff(crossings) / 2\n",
      "    crossings = crossings[1:]\n",
      "\n",
      "    if edge_type > 0:\n",
      "        crossings = crossings[crossings == 1]\n",
      "    elif edge_type < 0:\n",
      "        crossings = crossings[crossings == -1] / (-1)\n",
      "    else:\n",
      "        crossings = np.abs(crossings).fillna(0)\n",
      "        crossings = crossings[crossings != 0]\n",
      "\n",
      "    crossings = crossings.cumsum()\n",
      "    crossings = crossings.reindex(data.index)\n",
      "    crossings[0] = 0\n",
      "\n",
      "    return {\"result\": crossings.fillna(method=\"pad\").astype(\"int64\")}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/linear-interpolation-datetime-index_100_0362dc9d-9861-b2c2-e26b-2a42909346bf.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any, \"t\": DataType.String},\n",
      "    outputs={\"interpolation\": DataType.Any},\n",
      "    name=\"Linear Interpolation Datetime Index\",\n",
      "    description=\"Calculates the linear interpolation for some time frequency\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"0362dc9d-9861-b2c2-e26b-2a42909346bf\",\n",
      "    revision_group_id=\"0362dc9d-9861-b2c2-e26b-2a42909346bf\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, t):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...        {\n",
      "    ...             \"2019-08-01T15:20:12\": 1.2,\n",
      "    ...             \"2019-08-01T15:20:14\": 7.2,\n",
      "    ...             \"2019-08-01T15:20:15\": 0.3,\n",
      "    ...             \"2019-08-01T15:20:20\": 0.5,\n",
      "    ...        }\n",
      "    ...     ),\n",
      "    ...     t = \"s\"\n",
      "    ... )[\"interpolation\"]\n",
      "    2019-08-01 15:20:12    1.20\n",
      "    2019-08-01 15:20:13    4.20\n",
      "    2019-08-01 15:20:14    7.20\n",
      "    2019-08-01 15:20:15    0.30\n",
      "    2019-08-01 15:20:16    0.34\n",
      "    2019-08-01 15:20:17    0.38\n",
      "    2019-08-01 15:20:18    0.42\n",
      "    2019-08-01 15:20:19    0.46\n",
      "    2019-08-01 15:20:20    0.50\n",
      "    Freq: S, dtype: float64\n",
      "    \"\"\"\n",
      "    # write your code here.\n",
      "\n",
      "    data_date = data.copy()\n",
      "    try:\n",
      "        data_date.index = pd.to_datetime(data_date.index)\n",
      "    except (ValueError, TypeError):\n",
      "        raise TypeError(\"indices of data must be datetime\")\n",
      "\n",
      "    try:\n",
      "        return {\"interpolation\": data_date.resample(t).interpolate()}\n",
      "    except (ValueError):\n",
      "        raise ValueError(f\"t could not be parsed as frequency: {t}\")\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/time-length-operations/resample-datetime-index-using-mean_100_d48ce6ad-05ab-8bc1-fb79-c1960966f595.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any, \"t\": DataType.String},\n",
      "    outputs={\"resampled\": DataType.Any},\n",
      "    name=\"Resample Datetime Index using Mean\",\n",
      "    description=\"Resamples data for some time frequency by taking means\",\n",
      "    category=\"Time length operations\",\n",
      "    id=\"d48ce6ad-05ab-8bc1-fb79-c1960966f595\",\n",
      "    revision_group_id=\"d48ce6ad-05ab-8bc1-fb79-c1960966f595\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data, t):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...        [0, 10, 20, 30],\n",
      "    ...        index = pd.to_datetime(\n",
      "    ...            [\n",
      "    ...                \"2019-08-01T00:00:00\",\n",
      "    ...                \"2019-08-01T00:00:15\",\n",
      "    ...                \"2019-08-01T00:02:00\",\n",
      "    ...                \"2019-08-01T00:03:33\"\n",
      "    ...            ]\n",
      "    ...        )),\n",
      "    ...     t = \"min\"\n",
      "    ... )[\"resampled\"]\n",
      "    2019-08-01 00:00:00     5.0\n",
      "    2019-08-01 00:01:00     NaN\n",
      "    2019-08-01 00:02:00    20.0\n",
      "    2019-08-01 00:03:00    30.0\n",
      "    Freq: T, dtype: float64\n",
      "    \"\"\"\n",
      "    # write your code here.\n",
      "\n",
      "    data_date = data.copy()\n",
      "    try:\n",
      "        data_date.index = pd.to_datetime(data_date.index)\n",
      "    except (ValueError, TypeError):\n",
      "        raise TypeError(\"indices of data must be datetime\")\n",
      "\n",
      "    if not data.index.is_monotonic:\n",
      "        raise ValueError(\"data must be sorted by its index\")\n",
      "\n",
      "    try:\n",
      "        return {\"resampled\": data_date.resample(t).mean()}\n",
      "    except (ValueError):\n",
      "        raise ValueError(f\"t could not be parsed as frequency: {t}\")\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/consecutive-differences_100_ce801dcb-8ce1-14ad-029d-a14796dcac92.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Series},\n",
      "    outputs={\"diff\": DataType.Series},\n",
      "    name=\"Consecutive differences\",\n",
      "    description=\"Calculates the consecutive differences of a Series\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"ce801dcb-8ce1-14ad-029d-a14796dcac92\",\n",
      "    revision_group_id=\"ce801dcb-8ce1-14ad-029d-a14796dcac92\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:00\": 0.0,\n",
      "    ...            \"2019-08-01T15:20:01\": 5.0,\n",
      "    ...            \"2019-08-01T15:20:05\": 1.0,\n",
      "    ...            \"2019-08-01T15:20:09\": 9.0,\n",
      "    ...        }\n",
      "    ...     )\n",
      "    ... )[\"diff\"]\n",
      "    2019-08-01 15:20:01    5.0\n",
      "    2019-08-01 15:20:05   -4.0\n",
      "    2019-08-01 15:20:09    8.0\n",
      "    dtype: float64\n",
      "\n",
      "    \"\"\"\n",
      "    # write your code here.\n",
      "\n",
      "    data_dropna = data.dropna()\n",
      "\n",
      "    if pd.api.types.is_numeric_dtype(data_dropna.index.dtype):\n",
      "        data_dropna = data_dropna.sort_index()\n",
      "\n",
      "    else:\n",
      "        try:\n",
      "            data_dropna.index = pd.to_datetime(data_dropna.index)\n",
      "\n",
      "        except TypeError:\n",
      "            raise TypeError(\"indices of data must be numeric or datetime\")\n",
      "        data_dropna = data_dropna.sort_index()\n",
      "    data_diff = np.ediff1d(data_dropna.values)\n",
      "\n",
      "    return {\"diff\": pd.Series(data_diff, index=data_dropna.index[1:])}\n",
      "\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/e_100_13d3376a-9c08-d78f-8ad4-6d24fef504ca.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import math\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={},\n",
      "    outputs={\"e\": DataType.Float},\n",
      "    name=\"E\",\n",
      "    description=\"Returns the mathematical constant e = 2.718281...\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"13d3376a-9c08-d78f-8ad4-6d24fef504ca\",\n",
      "    revision_group_id=\"13d3376a-9c08-d78f-8ad4-6d24fef504ca\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main():\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main()\n",
      "    {'e': 2.718281828459045}\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "    return {\"e\": math.e}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/cumulative-sum_100_d2cc4c0d-303e-b0ad-fdba-73392e890b30.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any},\n",
      "    outputs={\"cum_sum\": DataType.Any},\n",
      "    name=\"Cumulative sum\",\n",
      "    description=\"Calculates the cumulative sum of a Series or DataFrame\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"d2cc4c0d-303e-b0ad-fdba-73392e890b30\",\n",
      "    revision_group_id=\"d2cc4c0d-303e-b0ad-fdba-73392e890b30\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:00\": 0.0,\n",
      "    ...            \"2019-08-01T15:20:01\": 5.0,\n",
      "    ...            \"2019-08-01T15:20:05\": 1.0,\n",
      "    ...            \"2019-08-01T15:20:09\": 9.0,\n",
      "    ...        }\n",
      "    ...     )\n",
      "    ... )[\"cum_sum\"]\n",
      "    2019-08-01 15:20:00     0.0\n",
      "    2019-08-01 15:20:01     5.0\n",
      "    2019-08-01 15:20:05     6.0\n",
      "    2019-08-01 15:20:09    15.0\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your code here.\n",
      "\n",
      "    if pd.api.types.is_numeric_dtype(data.index.dtype):\n",
      "        data_sort = data.sort_index()\n",
      "\n",
      "    else:\n",
      "        try:\n",
      "            data.index = pd.to_datetime(data.index)\n",
      "\n",
      "        except (ValueError, TypeError):\n",
      "            raise TypeError(\"indices of data must be numeric or datetime\")\n",
      "        data_sort = data.sort_index()\n",
      "    return {\"cum_sum\": data_sort.cumsum()}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/modulo_100_ebb5b2d1-7c25-94dd-ca81-6a9e5b21bc2f.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"a\": DataType.Any, \"b\": DataType.Integer},\n",
      "    outputs={\"modulo\": DataType.Any},\n",
      "    name=\"Modulo\",\n",
      "    description=\"Calculates the modulo to some given b\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"ebb5b2d1-7c25-94dd-ca81-6a9e5b21bc2f\",\n",
      "    revision_group_id=\"ebb5b2d1-7c25-94dd-ca81-6a9e5b21bc2f\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, a, b):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     a = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:12\": 25,\n",
      "    ...            \"2019-08-01T15:44:12\": None,\n",
      "    ...            \"2019-08-03T16:20:15\": -10,\n",
      "    ...            \"2019-08-05T12:00:34\": 4\n",
      "    ...        }\n",
      "    ...     ),\n",
      "    ...     b = 4 \n",
      "    ... )[\"modulo\"]\n",
      "    2019-08-01T15:20:12    1.0\n",
      "    2019-08-01T15:44:12    NaN\n",
      "    2019-08-03T16:20:15    2.0\n",
      "    2019-08-05T12:00:34    0.0\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "\n",
      "    return {\"modulo\": a % b}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/power_100_d24f40ae-4dfb-248f-6461-e67be3e5de8a.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"base\": DataType.Any, \"exponent\": DataType.Any},\n",
      "    outputs={\"power\": DataType.Any},\n",
      "    name=\"Power\",\n",
      "    description=\"Calculates the base to the power exponent\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"d24f40ae-4dfb-248f-6461-e67be3e5de8a\",\n",
      "    revision_group_id=\"d24f40ae-4dfb-248f-6461-e67be3e5de8a\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, base, exponent):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     base = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:12\": 3.0,\n",
      "    ...            \"2019-08-01T15:44:12\": None,\n",
      "    ...            \"2019-08-03T16:20:15\": 0.3,\n",
      "    ...            \"2019-08-05T12:00:34\": 0.5\n",
      "    ...        }\n",
      "    ...     ),\n",
      "    ...    exponent = 2\n",
      "    ... )[\"power\"]\n",
      "    2019-08-01T15:20:12    9.00\n",
      "    2019-08-01T15:44:12     NaN\n",
      "    2019-08-03T16:20:15    0.09\n",
      "    2019-08-05T12:00:34    0.25\n",
      "    dtype: float64\n",
      "    >>> main(base = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:12\": 3,\n",
      "    ...            \"2019-08-01T15:44:12\": 4,\n",
      "    ...            \"2019-08-03T16:20:15\": 9,\n",
      "    ...            \"2019-08-05T12:00:34\": 1,\n",
      "    ...        }\n",
      "    ...    ),\n",
      "    ...    exponent = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:12\": 2,\n",
      "    ...            \"2019-08-01T15:44:12\": 4,\n",
      "    ...            \"2019-08-03T16:20:15\": 0.5,\n",
      "    ...            \"2019-08-05T12:00:34\": 100000,\n",
      "    ...        }\n",
      "    ...    ),\n",
      "    ... )[\"power\"]\n",
      "    2019-08-01T15:20:12      9.0\n",
      "    2019-08-01T15:44:12    256.0\n",
      "    2019-08-03T16:20:15      3.0\n",
      "    2019-08-05T12:00:34      1.0\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    \n",
      "    # write your function code here.\n",
      "    return {\"power\": base ** exponent}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/exp_100_0da30127-b4d1-5e0d-2621-2c59b891c9b0.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import math\n",
      "import pandas as pd\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"data\": DataType.Any},\n",
      "    outputs={\"exp\": DataType.Any},\n",
      "    name=\"Exp\",\n",
      "    description=\"Calculates the exponential function of data\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"0da30127-b4d1-5e0d-2621-2c59b891c9b0\",\n",
      "    revision_group_id=\"0da30127-b4d1-5e0d-2621-2c59b891c9b0\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, data):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:12\": 0.0,\n",
      "    ...            \"2019-08-01T15:44:12\": None\n",
      "    ...        }\n",
      "    ...     )\n",
      "    ... )[\"exp\"]\n",
      "    2019-08-01T15:20:12    1.0\n",
      "    2019-08-01T15:44:12    NaN\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    # write your function code here.\n",
      "    return {\"exp\": math.e ** data}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/log-to-base_100_cd804f5d-76ea-1f8b-6adc-b4c4a78acaf4.json\n",
      "from hetdesrun.component.registration import register\n",
      "from hetdesrun.datatypes import DataType\n",
      "\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "\n",
      "# ***** DO NOT EDIT LINES BELOW *****\n",
      "# These lines may be overwritten if component details or inputs/outputs change.\n",
      "@register(\n",
      "    inputs={\"base\": DataType.Any, \"data\": DataType.Any},\n",
      "    outputs={\"log\": DataType.Any},\n",
      "    name=\"Log to base\",\n",
      "    description=\"Takes the logarithm of data to some given base\",\n",
      "    category=\"Arithmetic\",\n",
      "    id=\"cd804f5d-76ea-1f8b-6adc-b4c4a78acaf4\",\n",
      "    revision_group_id=\"cd804f5d-76ea-1f8b-6adc-b4c4a78acaf4\",\n",
      "    version_tag=\"1.0.0\"\n",
      ")\n",
      "def main(*, base, data):\n",
      "    # entrypoint function for this component\n",
      "    # ***** DO NOT EDIT LINES ABOVE *****\n",
      "    \"\"\" Usage example:\n",
      "    >>> main(\n",
      "    ...     base = 2,\n",
      "    ...     data = pd.Series(\n",
      "    ...        {\n",
      "    ...            \"2019-08-01T15:20:12\": 8.0,\n",
      "    ...            \"2019-08-01T15:44:12\": None,\n",
      "    ...            \"2019-08-03T16:20:15\": 1,\n",
      "    ...            \"2019-08-05T12:00:34\": 0.5\n",
      "    ...        }\n",
      "    ...     )\n",
      "    ... )[\"log\"]\n",
      "    2019-08-01T15:20:12    3.0\n",
      "    2019-08-01T15:44:12    NaN\n",
      "    2019-08-03T16:20:15    0.0\n",
      "    2019-08-05T12:00:34   -1.0\n",
      "    dtype: float64\n",
      "    >>> main(\n",
      "    ...     data = pd.Series(\n",
      "    ...         {\n",
      "    ...             \"2019-08-01T15:20:12\": 16,\n",
      "    ...             \"2019-08-01T15:44:12\": 4,\n",
      "    ...             \"2019-08-03T16:20:15\": 27,\n",
      "    ...             \"2019-08-05T12:00:34\": 1,\n",
      "    ...         }\n",
      "    ...     ),\n",
      "    ...     base = pd.Series(\n",
      "    ...         {\n",
      "    ...             \"2019-08-01T15:20:12\": 2,\n",
      "    ...             \"2019-08-01T15:44:12\": 2,\n",
      "    ...             \"2019-08-03T16:20:15\": 3,\n",
      "    ...             \"2019-08-05T12:00:34\": 22,\n",
      "    ...         }\n",
      "    ...     ),\n",
      "    ... )[\"log\"]\n",
      "    2019-08-01T15:20:12    4.0\n",
      "    2019-08-01T15:44:12    2.0\n",
      "    2019-08-03T16:20:15    3.0\n",
      "    2019-08-05T12:00:34    0.0\n",
      "    dtype: float64\n",
      "    \"\"\"\n",
      "    \n",
      "    # write your function code here.\n",
      "    return {\"log\": np.log(data) / np.log(base)}\n",
      "\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/sum-columns_100_619cbd38-26b4-3d5e-14a0-721224b13bc7.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/derivate_100_84bcdf4c-a068-3679-0cec-78bd6fcd3b48.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/nth-root_100_11152e31-cf25-4280-2b28-220319277011.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/ln_100_9f3ebd8c-92cf-deb1-09e9-d67ba16e9754.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/sqrt_100_40a03a56-5e3d-2695-07e4-9bcf0b1c3a39.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/pi_100_84337854-360a-bbc3-203c-f795d549076d.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/integrate_100_dd73bac2-cd9d-61c5-0aec-9dec6f337516.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/arithmetic/sum-up-series_100_878d85a2-2cf5-235b-d260-fd94c734cec9.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/greater-or-equal_100_f759e4c0-1468-0f2e-9740-41302b860193.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/greater_100_e6918e9e-aaaf-6f84-175a-fc2ac03ed85d.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/equality_100_9ccc8df5-5e68-46ff-bc2d-1fa82dae972c.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/select-column-from-dataframe_100_a652465e-b479-1cc9-bf82-41f7cedc4963.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/restrict-to-time-interval_100_bf469c0a-d17c-ca6f-59ac-9838b2ff67ac.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/smaller-or-equal_100_8a7e43b9-ce04-796e-6b73-5ce67547122a.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/inequality_100_4ec3ef23-6bea-872d-1905-c9c6d06dddef.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/filter_100_18260aab-bdd6-af5c-cac1-7bafde85188f.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/first-datetime-index_100_c7dbb92b-4a4c-c6d2-6665-5ee7d4eeab91.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/smaller_100_9f33cbbc-3935-e9f3-a682-99579e96a4d0.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic/last-datetime-index_100_c8e3bc64-b214-6486-31db-92a8888d8991.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/data-sources/get-r-dataset_100_80f4f916-4568-29bb-3f94-b487b0612232.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/data-sources/load-object_100_eb8e8d6b-ba7d-dc88-14dc-6839a471d5e0.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/models/predict-sklearn-trained-model_100_41e8bf16-0a16-6021-33c9-88c2f8336df8.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/models/decision-function-sklearn-trained-model_100_f35c4918-0a5d-d29c-f3fa-6cfcd425b0f7.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/data-quality/apply-substitution-timeseries_100_e1475799-eeab-8a18-97bf-69aa09d86a4a.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/anomaly-detection/isolation-forest_100_cdec1d55-5bb6-8e8d-4571-fbc0ebf5a354.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/anomaly-detection/simple-volatility-score_100_0c3c74d0-89b6-1948-fedd-753eaa47ca0e.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/anomaly-detection/alerts-from-score_100_38f168ef-cb06-d89c-79b3-0cd823f32e9d.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/trigonometric/sine_100_2cc88d07-b151-dc5b-d4c4-cfd95a043de3.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/trigonometric/cosine_100_1a83d0bb-2321-fd1a-8db4-22320b6eeb1c.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/trigonometric/arcustangent_100_8b974f17-5055-80f2-64f5-96c6eff93a35.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/trigonometric/arcussine_100_487008dc-1476-139c-5392-d5d0de1e6505.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/trigonometric/tangent_100_38eb0c5d-6182-0be2-3058-9b5bddc7842d.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/trigonometric/arcuscosine_100_ba0783de-93ab-0eb2-87fd-a5e09aff9d87.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/timeseries-plot-with-multiple-movable-x-and-y-axes_100_4e5115a2-2a45-4156-6f54-ff66c176daea.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/correlation-matrix-heatmap-plot_100_8debf23e-54e3-5fa1-bb57-6d41058c66b7.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/timeseries-dataframe-plot-with-multiple-y-axes_100_58e793bf-1aa7-316c-bc8a-f34a435fc8f0.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/contour-plot_100_f7530499-51b2-dd01-0d21-c24ee6f8c37e.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/timeseries-substitution-plot_100_3160c5a1-0cfb-7396-739a-a106c2a3e130.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/simple-scatter-map-plot_100_dc909fa2-93fa-3205-e31d-b05f944cbd29.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/dataframe-plot-with-multiple-x-and-y-axes_100_db80c471-924f-af19-e97b-06de42af6a30.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/2d-scatter-plot-colored-by-other-series_100_216f03cb-eec8-1907-f980-1df6abc2fb5b.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/compare-two-timeseries-plot_100_a432923f-4718-44ae-3c9c-9832e68724bb.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/univariate-linear-rul-regression-result-plot_100_9c3f88ce-1311-241e-18b7-acf7d3f5a051.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/timeseries-and-alerts-plot_100_95c006e4-5050-7722-6717-d1c6be2ba890.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/timeseries-interval-boxplots_100_56c937d5-37df-c70f-2113-808ef4a6d9ba.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/display-table_100_e0320729-10df-8979-4444-feb6fe7adc82.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/two-timeseries-with-two-y-axes-plot_100_5dc42708-34fd-ab82-bf2c-307fd66ad749.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/compare-timeshifted-timeseries_100_daed7280-7013-3be1-41c0-65e4628e0e1d.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/vertical-bar-plot_100_9f55f116-f22a-c94b-42b4-1f7c184da3bf.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/timeseries-dataframe-plot_100_16d6e587-25ea-d0df-f514-da9fef66ad80.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/2d-scatter-plot-colored-by-index_100_a408a19b-70fd-5a16-958c-193d678c2c2b.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/2d-grid-generator_100_096c6181-4ba5-0ee7-361a-3c32eee8c0c2.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/single-timeseries-plot_100_8fba9b51-a0f1-6c6c-a6d4-e224103b819c.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/visualization/pie-chart-plot_100_3b2fe728-5f36-64be-3963-df83918ff8a9.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/remaining-useful-life/univariate-linear-rul-regression_100_8d61a267-3a71-51cd-2817-48c320469d6b.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/divide_100_6d510037-229e-8e85-56f3-4a3797fdf315.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/abs_100_ea4a196f-5d94-d3cf-02e8-8c750414fc89.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/substract_100_10d27d69-e999-6654-3cef-427672aeb0fa.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/multiply_100_0438da97-f524-4a68-28c9-a88c81aa2c63.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/signum_100_24f115a8-45ad-21f2-c6ce-8edfc28f3b3f.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/round_100_50220962-16c0-c94f-8f0a-1e57d76e6878.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/basic-arithmetic/add_100_2abf72f6-68c9-7398-7175-165d31b3ced7.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/dataframe-to-series_100_152bc7df-708c-2ecb-1d5d-b69483fdd275.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through-float_100_2f511674-f766-748d-2de3-ad5e62e10a1a.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through_100_1946d5f8-44a8-724c-176f-16f3e49963af.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/combine-as-named-column-into-dataframe_100_0d08af64-3f34-cddc-354b-d6a26c3f1aab.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through-series_100_bfa27afc-dea8-b8aa-4b15-94402f0739b6.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/timeseries-dataframe_100_d71a0cef-1d56-818f-a1a5-dd6bb6d50399.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/combine-into-dataframe_100_68f91351-a1f5-9959-414a-2c72003f3226.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through-string_100_2b1b474f-ddf5-1f4d-fec4-17ef9122112b.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through-dataframe_100_7a1a818f-fa89-6062-1e0e-fc80539bbe0a.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/name-series_100_a4064897-66d3-9601-328e-5ae9036665c5.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/merge-dataframes-on-single-column_100_a573c94f-3039-1193-b068-bc496620c6ed.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through-integer_100_57eea09f-d28e-89af-4e81-2027697a3f0f.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/pass-through-boolean_100_8ea34104-2dd1-b4dc-8fd4-ed07bb967060.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/forget_100_d1fb4ae5-ef27-26b8-7a58-40b7cd8412e7.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/connectors/convert-series-to-dataframe_100_2f8c3864-8d45-5d68-c73f-229ef43bf944.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/data-sinks/store-object_100_26d99461-38a9-5e92-df4f-d0fd2752879e.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/index-operations/restrict-to-common-index_100_ac86c25c-a510-e46e-ff3a-f9bbb4c26a24.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/index-operations/timeshifted-value-table_100_e4541a9d-7b3e-3dd6-869d-eff30ad997c3.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/index-operations/sort-by-index_100_7f315341-d095-1f4b-b72c-e85dc3d7c508.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/regression/linear-regression_100_10ab5fc1-9654-8a46-1c36-03660b4a2681.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/regression/linear-regression-two-series_100_ff182e84-913d-e799-5722-98a5d2e3ad09.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/physics/time-to-length_100_517fb2a7-ec6a-eced-c2ea-eb6dc5e76b0c.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/mavg-outlier-filter_100_11b9c01e-8e32-25a9-9625-97a5654230be.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/drop-duplicates_100_72570287-ecb6-4c74-3902-ace451662138.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/cut-values-below-limit_100_07f979e0-11bd-f91a-1a8f-52b4ef883d74.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/highpass-filter_100_417d44a2-1701-2e5b-bee8-7ce1a4dc1d0e.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/drop-nan-values_100_e8b1d655-803c-e79f-5c15-62aec3a4c27d.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/cut-values-above-limit_100_e3323561-276e-d4a8-8417-badedbbd3c98.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/mavg-smoothing_100_41f4c453-e4e7-f07d-df77-c89cb42cb3ac.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/reduce-data-set-by-leaving-out-values_100_0a871bb6-b59c-e94d-40fd-a6673d1713c7.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/filters/lowpass-filter_100_a4a8cfa7-3b18-dc8d-2985-9a8be889686a.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-median-number_100_c9736810-73d8-b109-3822-96a5bf0a6d1c.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/average_100_bbf3e562-439a-9662-616f-969bf79d57a2.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-maximum-time_100_037887de-bbee-caeb-f0bd-7060d59f60e9.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-average-time_100_a2ba0da0-5a9a-60e9-6af5-e07917988021.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/standard-scale_100_6c4ce4d5-e73f-210e-48a8-230c8e5088ef.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-standard-deviation-number_100_acfd3d99-0a6c-97ae-7bcf-de08ea9ce4ee.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/maximum_100_d72939c2-1b0c-065e-556a-c9974c179c0f.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-minimum-number_100_e79f021a-93a8-d55b-1032-19d91d78fd51.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-maximum-number_100_468f917b-7b99-9394-d600-50ee05237041.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/minimum_100_375819f5-deb3-0d5f-8661-22d202b39c54.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/standard-deviation_100_462e4cd5-1772-a925-6d26-8d33011111cd.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-median-time_100_1feea93c-a6e7-4fec-c01c-6f30037f8cca.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-average-number_100_c9c8eb62-a694-3108-1c64-957bdd514c2b.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-standard-deviation-time_100_5eb8ca16-bbc7-94b1-3d82-6f074cd63456.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/moving-minimum-time_100_33d7c458-762c-7555-7a20-26ef0708bc28.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/components/statistic/median_100_dc9dcd3d-88a0-539c-c5d9-bb52c0eded33.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/connectors/combine-two-series-into-dataframe_100_09b29726-4373-4652-82c8-7aa3e3f91676.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/connectors/combine-two-series-as-named-columns-into-dataframe_100_45f4f0c1-3fda-4c3b-8187-c590610e6975.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/examples/univariate-linear-rul-regression-example_100_806df1b9-2fc8-4463-943f-3d258c569663.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/examples/visualization-demo_100_7ccb7acb-4779-4931-b436-2d4d5172607b.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/examples/linear-rul-from-last-positive-step_100_3d504361-e351-4d52-8734-391aa47e8f24.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/examples/data-from-last-positive-step_100_2cbb87e7-ea99-4404-abe1-be550f22763f.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/examples/iso-forest-example_100_67c14cf2-cd4e-410e-9aca-6664273ccc3f.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n",
      "./transformations/workflows/examples/volatility-detection-example_100_79ce1eb1-3ef8-4c74-9114-c856fd88dc89.json\n",
      "... no merge conflict\n",
      "==================================================================================================\n"
     ]
    }
   ],
   "source": [
    "json_files = []\n",
    "for root, _, files in os.walk(\"./transformations\"):\n",
    "    for file in files:\n",
    "        if file.endswith(\".json\"):\n",
    "            json_files.append(os.path.join(root, file))\n",
    "\n",
    "for file in json_files:\n",
    "    print(file)\n",
    "    with open(file, \"r\") as f:\n",
    "        file_content = f.read()\n",
    "    if \"<<<<<<< HEAD\\n\" in file_content:\n",
    "        split_at_top_string = \"<<<<<<< HEAD\\n\"\n",
    "        split_at_mid_string = \"=======\\n\"\n",
    "        split_at_low_string = '>>>>>>> parent of deb96cc... move doctest docstring below \"do not edit lines above\" line'\n",
    "        file_content_top, file_content_not_top = file_content.split(split_at_top_string)\n",
    "        file_content_neither_top_nor_bottom, file_content_bottom = file_content_not_top.split(\n",
    "            split_at_low_string\n",
    "        )\n",
    "        _, file_content_mid = file_content_neither_top_nor_bottom.split(split_at_mid_string)\n",
    "        file_content = file_content_top + file_content_mid + file_content_bottom\n",
    "        tr_json = json.loads(file_content)\n",
    "        old_code = tr_json[\"content\"]\n",
    "#         print(old_code)\n",
    "        split_code_at_top = \"    # entrypoint function for this component\\n\"\n",
    "        split_code_at_bottom = \"    # ***** DO NOT EDIT LINES ABOVE *****\\n\"\n",
    "        code_top, code_not_top = old_code.split(split_code_at_top)\n",
    "        code_mid, code_bottom = code_not_top.split(split_code_at_bottom)\n",
    "        code_to_be_preserved = code_top + split_code_at_bottom + code_mid + code_bottom\n",
    "#         print(code_to_be_preserved)\n",
    "        tr = TransformationRevision(**tr_json)\n",
    "        updated_code = update_code(code_to_be_preserved, ComponentInfo.from_tr(tr))\n",
    "#         print(updated_code)\n",
    "        tr.content = updated_code\n",
    "#         print(tr.content)\n",
    "        tr_json = json.dumps(tr.dict(exclude_unset=True), cls=TREncoder, indent=2, sort_keys=True)\n",
    "#         with open(file, \"w\", encoding=\"utf8\") as f:\n",
    "#             json.dump(json.loads(tr_json), f, cls=TREncoder, indent=2, sort_keys=True)\n",
    "    else:\n",
    "        print(\"... no merge conflict\")\n",
    "    print(\"==================================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377c995b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
